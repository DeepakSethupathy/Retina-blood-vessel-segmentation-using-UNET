{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "from random import seed\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading vessel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21_manual1.jpg', '22_manual1.jpg', '23_manual1.jpg', '24_manual1.jpg', '25_manual1.jpg', '26_manual1.jpg', '27_manual1.jpg', '28_manual1.jpg', '29_manual1.jpg', '30_manual1.jpg', '31_manual1.jpg', '32_manual1.jpg', '33_manual1.jpg', '34_manual1.jpg', '35_manual1.jpg', '36_manual1.jpg', '37_manual1.jpg', '38_manual1.jpg', '39_manual1.jpg', '40_manual1.jpg']\n",
      "['C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\21_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\22_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\23_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\24_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\25_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\26_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\27_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\28_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\29_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\30_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\31_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\32_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\33_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\34_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\35_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\36_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\37_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\38_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\39_manual1.jpg', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\1st_manual\\\\\\\\40_manual1.jpg']\n"
     ]
    }
   ],
   "source": [
    "training_vessels=os.listdir(r'C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\train\\1st_manual')\n",
    "path=r'C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\train\\1st_manual\\\\'\n",
    "print(training_vessels)\n",
    "\n",
    "list_path=[]\n",
    "for i in training_vessels:\n",
    "    list_path.append(str(path+str(i)))\n",
    "print(list_path)\n",
    "images=np.zeros((len(list_path),584,565,1),dtype=np.uint8)\n",
    "\n",
    "#reading images, convert to binary and add to array images.\n",
    "for i in range(len(list_path)):\n",
    "    temp=cv2.imread(list_path[i],0)\n",
    "    (thresh, blackAndWhiteImage) = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY) \n",
    "    temp = resize(blackAndWhiteImage, (584, 565,1), mode='constant', preserve_range=True)\n",
    "    images[i]=temp\n",
    "    \n",
    "#images[i]=cv2.imread(list_path[i],0)\n",
    "#one_image=cv2.imread(r'C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\train\\1st_manual\\21_manual1.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vessels images found =20\n"
     ]
    }
   ],
   "source": [
    "print('Number of vessels images found ='+str(len(images)))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    cv2.imshow('image'+str(i),images[i])\n",
    "    cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Fundus images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21_training.tif', '22_training.tif', '23_training.tif', '24_training.tif', '25_training.tif', '26_training.tif', '27_training.tif', '28_training.tif', '29_training.tif', '30_training.tif', '31_training.tif', '32_training.tif', '33_training.tif', '34_training.tif', '35_training.tif', '36_training.tif', '37_training.tif', '38_training.tif', '39_training.tif', '40_training.tif']\n",
      "['C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\21_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\22_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\23_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\24_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\25_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\26_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\27_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\28_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\29_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\30_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\31_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\32_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\33_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\34_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\35_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\36_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\37_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\38_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\39_training.tif', 'C:\\\\Users\\\\Deepak Sethupathy\\\\Documents\\\\College\\\\Summer_internship\\\\vessel_segmentation\\\\train\\\\images\\\\\\\\40_training.tif']\n"
     ]
    }
   ],
   "source": [
    "fundus=os.listdir(r'C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\train\\images')\n",
    "path2=r'C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\train\\images\\\\'\n",
    "print(fundus)\n",
    "list_path2=[]\n",
    "\n",
    "for i in fundus:\n",
    "    list_path2.append(str(path2+str(i)))\n",
    "print(list_path2)\n",
    "fundus_images=np.zeros((len(list_path2),584,565,1),dtype=np.uint8)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "#reading images, convert to gray scale, apply CLAHE add to array fundus_images images.\n",
    "for i in range(len(list_path2)):\n",
    "    t=cv2.imread(list_path2[i],0)\n",
    "    t1=clahe.apply(t)\n",
    "    t2=resize(t1, (584, 565,1), mode='constant', preserve_range=True)\n",
    "    fundus_images[i]=t2\n",
    "    #fundus_images[i]=cv2.imread(list_path2[i],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fundus images found =20\n"
     ]
    }
   ],
   "source": [
    "print('Number of fundus images found ='+str(len(fundus_images)))\n",
    "for i in range(len(fundus_images)):\n",
    "    cv2.imshow('image'+str(i),fundus_images[i])\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Patches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total 2000 patches of size 48x48. 100 patches from each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=np.zeros((2000,48,48,1),dtype=np.uint8)\n",
    "ves=np.zeros((2000,48,48,1))\n",
    "seed(0)\n",
    "itr=0\n",
    "\n",
    "for j in range(20):\n",
    "    one_image=images[j]\n",
    "    two_image=fundus_images[j]\n",
    "    for i in range(100):\n",
    "        x=randint(0,536)\n",
    "        y=randint(0,516)\n",
    "        real[itr]=np.copy(two_image[x:x+48,y:y+48,:])\n",
    "        ves[itr]=np.copy(one_image[x:x+48,y:y+48,:])\n",
    "        itr=itr+1\n",
    "ves=ves/255      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(ves)) \n",
    "print(np.min(ves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing few images for test\n",
    "for i in range (200,205):\n",
    "    cv2.imshow('image',real[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('image2',ves[i])\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 48, 48, 1)\n",
      "(2000, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#verifying shape\n",
    "print(real.shape)\n",
    "print(ves.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and training the UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 48, 48, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 48, 32)   320         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 48, 48, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 48, 48, 32)   9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 24, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 24, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 24, 24, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 24, 64)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 12, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 12, 12, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 12, 12, 128)  147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 6, 6, 256)    295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 6, 256)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 6, 6, 256)    590080      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 256)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 512)    1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 3, 3, 512)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 512)    2359808     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 6, 6, 256)    524544      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 6, 512)    0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 6, 256)    1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 6, 6, 256)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 6, 6, 256)    590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  131200      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 12, 12, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 24, 24, 64)   32832       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 24, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 24, 24, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 24, 24, 64)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 24, 24, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 48, 48, 32)   8224        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 48, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 48, 48, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 48, 48, 32)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 48, 48, 32)   9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 48, 48, 1)    33          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39302, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 19s - loss: 0.4839 - accuracy: 0.8605 - val_loss: 0.3930 - val_accuracy: 0.8944\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39302 to 0.32556, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.3631 - accuracy: 0.9019 - val_loss: 0.3256 - val_accuracy: 0.8944\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32556 to 0.28306, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.2903 - accuracy: 0.9019 - val_loss: 0.2831 - val_accuracy: 0.8944\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28306 to 0.27303, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.2630 - accuracy: 0.9028 - val_loss: 0.2730 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27303 to 0.27084, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.2836 - accuracy: 0.9013 - val_loss: 0.2708 - val_accuracy: 0.8944\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27084 to 0.25918, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.2652 - accuracy: 0.9019 - val_loss: 0.2592 - val_accuracy: 0.8944\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25918\n",
      "1600/1600 - 8s - loss: 0.2436 - accuracy: 0.9042 - val_loss: 0.2626 - val_accuracy: 0.8985\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25918 to 0.25499, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 10s - loss: 0.2146 - accuracy: 0.9200 - val_loss: 0.2550 - val_accuracy: 0.9125\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25499 to 0.18201, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1936 - accuracy: 0.9281 - val_loss: 0.1820 - val_accuracy: 0.9264\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18201\n",
      "1600/1600 - 8s - loss: 0.1749 - accuracy: 0.9327 - val_loss: 0.2015 - val_accuracy: 0.9252\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18201\n",
      "1600/1600 - 8s - loss: 0.1619 - accuracy: 0.9353 - val_loss: 0.1837 - val_accuracy: 0.9304\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18201\n",
      "1600/1600 - 8s - loss: 0.1577 - accuracy: 0.9362 - val_loss: 0.1891 - val_accuracy: 0.9298\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.18201 to 0.15576, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1555 - accuracy: 0.9366 - val_loss: 0.1558 - val_accuracy: 0.9342\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15576\n",
      "1600/1600 - 8s - loss: 0.1501 - accuracy: 0.9373 - val_loss: 0.1681 - val_accuracy: 0.9350\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.15576 to 0.14807, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1481 - accuracy: 0.9378 - val_loss: 0.1481 - val_accuracy: 0.9347\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.14807\n",
      "1600/1600 - 8s - loss: 0.1462 - accuracy: 0.9382 - val_loss: 0.1546 - val_accuracy: 0.9365\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.14807\n",
      "1600/1600 - 8s - loss: 0.1439 - accuracy: 0.9388 - val_loss: 0.1548 - val_accuracy: 0.9363\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.14807\n",
      "1600/1600 - 8s - loss: 0.1409 - accuracy: 0.9390 - val_loss: 0.1821 - val_accuracy: 0.9353\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14807\n",
      "1600/1600 - 8s - loss: 0.1406 - accuracy: 0.9393 - val_loss: 0.1529 - val_accuracy: 0.9377\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.14807 to 0.14052, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1366 - accuracy: 0.9400 - val_loss: 0.1405 - val_accuracy: 0.9379\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14052\n",
      "1600/1600 - 8s - loss: 0.1368 - accuracy: 0.9400 - val_loss: 0.1493 - val_accuracy: 0.9382\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14052\n",
      "1600/1600 - 8s - loss: 0.1351 - accuracy: 0.9406 - val_loss: 0.1439 - val_accuracy: 0.9388\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.14052 to 0.13700, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1330 - accuracy: 0.9411 - val_loss: 0.1370 - val_accuracy: 0.9385\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.13700 to 0.13281, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1327 - accuracy: 0.9411 - val_loss: 0.1328 - val_accuracy: 0.9388\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13281\n",
      "1600/1600 - 8s - loss: 0.1316 - accuracy: 0.9415 - val_loss: 0.1362 - val_accuracy: 0.9390\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13281 to 0.13023, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1293 - accuracy: 0.9421 - val_loss: 0.1302 - val_accuracy: 0.9392\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13023\n",
      "1600/1600 - 8s - loss: 0.1289 - accuracy: 0.9423 - val_loss: 0.1329 - val_accuracy: 0.9399\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.13023 to 0.12395, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 10s - loss: 0.1270 - accuracy: 0.9427 - val_loss: 0.1239 - val_accuracy: 0.9408\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12395\n",
      "1600/1600 - 8s - loss: 0.1257 - accuracy: 0.9431 - val_loss: 0.1250 - val_accuracy: 0.9400\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12395 to 0.12004, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 11s - loss: 0.1237 - accuracy: 0.9436 - val_loss: 0.1200 - val_accuracy: 0.9407\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12004 to 0.11871, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1236 - accuracy: 0.9438 - val_loss: 0.1187 - val_accuracy: 0.9406\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11871\n",
      "1600/1600 - 8s - loss: 0.1196 - accuracy: 0.9447 - val_loss: 0.1219 - val_accuracy: 0.9406\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11871\n",
      "1600/1600 - 8s - loss: 0.1181 - accuracy: 0.9454 - val_loss: 0.1188 - val_accuracy: 0.9403\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11871 to 0.11710, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1162 - accuracy: 0.9458 - val_loss: 0.1171 - val_accuracy: 0.9400\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11710 to 0.11689, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1151 - accuracy: 0.9461 - val_loss: 0.1169 - val_accuracy: 0.9399\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11689\n",
      "1600/1600 - 8s - loss: 0.1131 - accuracy: 0.9467 - val_loss: 0.1175 - val_accuracy: 0.9377\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11689\n",
      "1600/1600 - 8s - loss: 0.1124 - accuracy: 0.9470 - val_loss: 0.1182 - val_accuracy: 0.9390\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11689 to 0.11487, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1126 - accuracy: 0.9468 - val_loss: 0.1149 - val_accuracy: 0.9386\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.11487 to 0.11077, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1098 - accuracy: 0.9476 - val_loss: 0.1108 - val_accuracy: 0.9402\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11077\n",
      "1600/1600 - 8s - loss: 0.1085 - accuracy: 0.9479 - val_loss: 0.1120 - val_accuracy: 0.9410\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.11077 to 0.10749, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.1074 - accuracy: 0.9482 - val_loss: 0.1075 - val_accuracy: 0.9421\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1055 - accuracy: 0.9488 - val_loss: 0.1108 - val_accuracy: 0.9413\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1053 - accuracy: 0.9488 - val_loss: 0.1109 - val_accuracy: 0.9401\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1045 - accuracy: 0.9488 - val_loss: 0.1084 - val_accuracy: 0.9405\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1037 - accuracy: 0.9492 - val_loss: 0.1140 - val_accuracy: 0.9380\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1017 - accuracy: 0.9496 - val_loss: 0.1084 - val_accuracy: 0.9401\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1006 - accuracy: 0.9500 - val_loss: 0.1077 - val_accuracy: 0.9416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.1013 - accuracy: 0.9496 - val_loss: 0.1083 - val_accuracy: 0.9403\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.0986 - accuracy: 0.9504 - val_loss: 0.1076 - val_accuracy: 0.9413\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10749\n",
      "1600/1600 - 8s - loss: 0.0967 - accuracy: 0.9508 - val_loss: 0.1095 - val_accuracy: 0.9375\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10749 to 0.10642, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.0961 - accuracy: 0.9510 - val_loss: 0.1064 - val_accuracy: 0.9422\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.10642 to 0.10522, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.0949 - accuracy: 0.9512 - val_loss: 0.1052 - val_accuracy: 0.9403\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10522\n",
      "1600/1600 - 8s - loss: 0.0941 - accuracy: 0.9512 - val_loss: 0.1074 - val_accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10522\n",
      "1600/1600 - 8s - loss: 0.0940 - accuracy: 0.9513 - val_loss: 0.1085 - val_accuracy: 0.9418\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.10522 to 0.10515, saving model to model_for_nuclei.h5\n",
      "1600/1600 - 9s - loss: 0.0916 - accuracy: 0.9520 - val_loss: 0.1052 - val_accuracy: 0.9405\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0912 - accuracy: 0.9519 - val_loss: 0.1068 - val_accuracy: 0.9398\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0897 - accuracy: 0.9523 - val_loss: 0.1071 - val_accuracy: 0.9417\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0884 - accuracy: 0.9526 - val_loss: 0.1073 - val_accuracy: 0.9405\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0871 - accuracy: 0.9525 - val_loss: 0.1103 - val_accuracy: 0.9422\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0874 - accuracy: 0.9526 - val_loss: 0.1074 - val_accuracy: 0.9427\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0860 - accuracy: 0.9530 - val_loss: 0.1114 - val_accuracy: 0.9381\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0848 - accuracy: 0.9530 - val_loss: 0.1093 - val_accuracy: 0.9390\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0835 - accuracy: 0.9533 - val_loss: 0.1070 - val_accuracy: 0.9410\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0816 - accuracy: 0.9536 - val_loss: 0.1078 - val_accuracy: 0.9423\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0808 - accuracy: 0.9539 - val_loss: 0.1120 - val_accuracy: 0.9379\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0824 - accuracy: 0.9535 - val_loss: 0.1137 - val_accuracy: 0.9402\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0797 - accuracy: 0.9539 - val_loss: 0.1107 - val_accuracy: 0.9406\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0787 - accuracy: 0.9541 - val_loss: 0.1120 - val_accuracy: 0.9402\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0765 - accuracy: 0.9545 - val_loss: 0.1098 - val_accuracy: 0.9416\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0753 - accuracy: 0.9547 - val_loss: 0.1095 - val_accuracy: 0.9410\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0745 - accuracy: 0.9547 - val_loss: 0.1093 - val_accuracy: 0.9418\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0733 - accuracy: 0.9550 - val_loss: 0.1115 - val_accuracy: 0.9401\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0725 - accuracy: 0.9551 - val_loss: 0.1094 - val_accuracy: 0.9408\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0713 - accuracy: 0.9553 - val_loss: 0.1146 - val_accuracy: 0.9390\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0705 - accuracy: 0.9555 - val_loss: 0.1156 - val_accuracy: 0.9376\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0697 - accuracy: 0.9555 - val_loss: 0.1137 - val_accuracy: 0.9416\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0680 - accuracy: 0.9558 - val_loss: 0.1170 - val_accuracy: 0.9405\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0675 - accuracy: 0.9560 - val_loss: 0.1200 - val_accuracy: 0.9376\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0666 - accuracy: 0.9561 - val_loss: 0.1196 - val_accuracy: 0.9409\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0658 - accuracy: 0.9564 - val_loss: 0.1202 - val_accuracy: 0.9387\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0652 - accuracy: 0.9564 - val_loss: 0.1216 - val_accuracy: 0.9387\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0638 - accuracy: 0.9567 - val_loss: 0.1285 - val_accuracy: 0.9382\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0630 - accuracy: 0.9567 - val_loss: 0.1206 - val_accuracy: 0.9405\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0629 - accuracy: 0.9569 - val_loss: 0.1259 - val_accuracy: 0.9378\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0618 - accuracy: 0.9571 - val_loss: 0.1286 - val_accuracy: 0.9396\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0607 - accuracy: 0.9573 - val_loss: 0.1275 - val_accuracy: 0.9399\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0598 - accuracy: 0.9576 - val_loss: 0.1280 - val_accuracy: 0.9371\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0589 - accuracy: 0.9576 - val_loss: 0.1294 - val_accuracy: 0.9400\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0580 - accuracy: 0.9580 - val_loss: 0.1250 - val_accuracy: 0.9388\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0577 - accuracy: 0.9579 - val_loss: 0.1411 - val_accuracy: 0.9406\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0572 - accuracy: 0.9582 - val_loss: 0.1358 - val_accuracy: 0.9393\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0563 - accuracy: 0.9582 - val_loss: 0.1306 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0555 - accuracy: 0.9585 - val_loss: 0.1323 - val_accuracy: 0.9388\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0548 - accuracy: 0.9588 - val_loss: 0.1368 - val_accuracy: 0.9389\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0539 - accuracy: 0.9588 - val_loss: 0.1320 - val_accuracy: 0.9387\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0535 - accuracy: 0.9590 - val_loss: 0.1413 - val_accuracy: 0.9389\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0522 - accuracy: 0.9593 - val_loss: 0.1424 - val_accuracy: 0.9391\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0522 - accuracy: 0.9592 - val_loss: 0.1400 - val_accuracy: 0.9392\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0515 - accuracy: 0.9596 - val_loss: 0.1381 - val_accuracy: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10515\n",
      "1600/1600 - 8s - loss: 0.0509 - accuracy: 0.9596 - val_loss: 0.1401 - val_accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "inputs = tf.keras.layers.Input((48, 48, 1))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.2)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.2)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.2)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Expansive path \n",
    "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.2)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.2)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=2, save_best_only=True)\n",
    "#callbacks = myCallback()\n",
    "results = model.fit(real, ves, validation_split=0.2, batch_size=60, epochs=100,verbose=2, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\Deepak Sethupathy\\Documents\\College\\Summer_internship\\vessel_segmentation\\best_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 2ms/sample\n",
      "(2000, 48, 48, 1)\n",
      "(2000, 48, 48, 1)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "pred=model.predict(real,verbose=1)\n",
    "print(pred.shape)\n",
    "thresh= (pred > 0.5).astype(np.uint8)\n",
    "print(thresh.shape)\n",
    "teo=thresh[55]\n",
    "(thresh, two) = cv2.threshold(teo, 0, 255, cv2.THRESH_BINARY)\n",
    "print(two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing Predcition and ground truth\n",
    "cv2.imshow('predicted',two)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('real',ves[55])\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = results.history['accuracy']\n",
    "val_acc = results.history['val_accuracy']\n",
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "#plt.figure()\n",
    "plt.savefig('foo.png', bbox_inches='tight')\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "intern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
